personal:
  name: "Adrian Villanueva Martinez"
  title: "Senior Software Engineer"
  nationality: "Spain ðŸ‡ªðŸ‡¸"
  location: "Tokyo, Japan ðŸ‡¯ðŸ‡µ"
  summary: "Experienced Software Engineer with deep expertise in cloud-native data platforms, data engineering, and MLOps. Based in Tokyo, delivering European engineering excellence and driving large-scale adoption of high-impact systems across organizations. Skilled in designing resilient infrastructure, building powerful SDKs, and enabling company-wide platform usability."
  email: "adrian.villanueva.martinez@outlook.com"

experience:
  - company: "Woven by Toyota"
    position: "Data Engineer"
    location: "Tokyo, Japan"
    startDate: "2024-08"
    endDate: "Present"
    highlights:
      - "Built a scalable, cloud-native data mesh platform on AWS and Databricks, adopted company-wide to enable governed, high-quality data sharing across domains"
      - "Developed a multi-language Kafka ingestion SDK (Rust core with Python, Java, TypeScript, and Go bindings), deployed org-wide for real-time ingestion across heterogeneous systems"
      - "Designed and implemented CI/CD pipelines for ML and data workflows in Databricks, integrating deployment and lifecycle tracking with MLflow"
      - "Improved platform resilience through automated data reconciliation, OpenTelemetry instrumentation, and enforcement of data contracts"
      - "Led development of self-service capabilities, including automated provisioning of Kafka topics, access control groups, and data product registration, reducing onboarding friction across the org"
      - "Created platform documentation, naming conventions, and onboarding guides to support self-serve adoption by engineers, analysts, and ML practitioners"

  - company: "Albert Heijn"
    position: "Data Platform Engineer"
    location: "Amsterdam, Netherlands"
    startDate: "2022-03"
    endDate: "2024-06"
    highlights:
      - "Managed a company-wide data platform built on Azure and Databricks, supporting large-scale batch and real-time pipelines"
      - "Built reusable Terraform modules and automated infrastructure provisioning to reduce deployment time and enforce compliance"
      - "Created observability tooling using Python and Kusto to ensure data quality and regulatory compliance across data products"
      - "Implemented CI/CD with GitHub Actions and ArgoCD, automating deployment of services and pipelines to Kubernetes clusters"
      - "Worked closely with analysts and data scientists to productionize ML pipelines and deploy feature engineering workflows"

  - company: "Dashmote"
    position: "Data Engineer"
    location: "Amsterdam, Netherlands"
    startDate: "2021-09"
    endDate: "2022-03"
    highlights:
      - "Migrated legacy Airflow pipelines to PySpark for scalable data processing and analytics workflows"
      - "Optimized Docker builds and CI pipelines to cut build time and reduce cloud costs by applying multi-stage techniques"
      - "Designed and deployed a governed data lake on S3 with robust schema management and access controls"
      - "Collaborated with data scientists to automate training data pipelines and streamline model experimentation"

  - company: "Ernst & Young (EY)"
    position: "Software Developer (Faas Tech)"
    location: "Madrid, Spain"
    startDate: "2019-06"
    endDate: "2020-06"
    highlights:
      - "Built ETL pipelines in Python, SQL, and Java to automate financial reporting workflows across global client accounts"
      - "Trained and deployed ML models for forecasting and risk scoring in regulated environments"
      - "Built and deployed full-stack data visualization tools on Linux for internal analytics teams"
      - "Participated in project planning with clients, translating business goals into deliverable data products"

education:
  - institution: "Universidad Europea de Madrid"
    degree: "Bachelor's in Computer Science"
    location: "Madrid, Spain"
    startDate: "2015"
    endDate: "2020"

skills:
  languages: ["Python", "TypeScript", "Rust", "Java", "SQL", "Go", "Bash", "C"]
  frameworks: ["Next.js", "React", "FastAPI", "Apache Airflow", "Pyspark"]
  cloud: ["AWS", "Azure", "GCP"]
  tools: ["Databricks", "Docker", "Terraform", "Kubernetes"]
  mlops: ["MLflow"]
  databases: ["AWS Athena", "SQL-based databases", "Redis"]
  monitoring: ["OpenTelemetry", "Prometheus", "Grafana"]
  CI/CD: ["GitHub Actions", "Jenkins", "ArgoCD"]
  other: ["Linux (Ubuntu, CentOS)", "Windows Server"]

languages:
  - name: "Spanish"
    level: "Native"
  - name: "English"
    level: "Professional"
  - name: "Japanese"
    level: "Basic"
  - name: "Dutch"
    level: "Basic"
